{"meta":{"title":"会飞的鱼","subtitle":null,"description":null,"author":null,"url":"http://yoursite.com"},"pages":[{"title":"","date":"2019-02-18T06:41:12.437Z","updated":"2019-02-18T06:41:12.437Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"","date":"2019-02-18T06:41:12.437Z","updated":"2019-02-18T06:41:12.437Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ejabberd编码风格","slug":"ejabberd编码风格","date":"2019-03-02T09:22:53.000Z","updated":"2019-03-02T09:22:53.000Z","comments":true,"path":"2019/03/02/ejabberd编码风格/","link":"","permalink":"http://yoursite.com/2019/03/02/ejabberd编码风格/","excerpt":"ejabberd编码风格Erlang编码规则 ejabberd编码风格 更改别人的代码时，保持现有风格。 2个空格缩进 参数间放置空格 123456-module(spaces).-export([bad/3, good/3]).% @doc no spacesbad(_My,_Space,_Bar)-&gt;[is,'not',working].% @doc spaces!!good(_Hey, _Now, _It) -&gt; [\"works \" ++ \"again, \" | [hooray]].","text":"ejabberd编码风格Erlang编码规则 ejabberd编码风格 更改别人的代码时，保持现有风格。 2个空格缩进 参数间放置空格 123456-module(spaces).-export([bad/3, good/3]).% @doc no spacesbad(_My,_Space,_Bar)-&gt;[is,'not',working].% @doc spaces!!good(_Hey, _Now, _It) -&gt; [\"works \" ++ \"again, \" | [hooray]]. 行尾不留空白 每行100列，100字符为最大值 case表达式执行小函数 12345678910111213141516171819202122232425-module(smaller_functions).-export([bad/0, bad/1, good/0, good/1]).%% @doc function with just a casebad(Arg) -&gt; case Arg of this_one -&gt; should:be(a, function, clause); and_this_one -&gt; should:be(another, function, clause) end.%% @doc usage of pattern matchinggood(this_one) -&gt; is:a(function, clause);good(and_this_one) -&gt; is:another(function, clause).%% @doc function with an internal casebad() -&gt; InitialArg = some:initial_arg(), InternalResult = case InitialArg of this_one -&gt; should:be(a, function, clause); and_this_one -&gt; should:be(another, function, clause) end, some:modification(InternalResult).%% @doc usage of function clauses instead of an internal casegood() -&gt; InitialArg = some:initial_arg(), InternalResult = good(InitialArg), some:modification(InternalResult). 模块功能单一，不要把无关功能放在一个模块中 单元测试，一个函数测试一个点，不要把多个测试点写一起 按功能为模块分组，设置子目录 头文件 不应包含类型定义、记录定义、函数定义； 可能包含红定义，但应避免使用宏； 在头文件中包含记录定义可促进跨模块共享这些记录的内部细节，增加耦合并防止封装，从而使更改和维护代码变得更加困难。记录应该在他们自己的模块中定义，这些模块应该提供不透明的数据类型和访问和操作记录的功能。 函数定义绝对不应包含在头文件中，因为它会导致代码重复。 程序的函数调用图应该努力成为有向无环图 123456789101112131415161718192021222324252627-module(spaghetti).-export([bad/0, good/0]).bad() -&gt; Client = active_user:get_current_client(), [binary_to_list(Org) || Org &lt;- autocomplete_db:members( case Client of home_client -&gt; &lt;&lt;\"our:organizations\"&gt;&gt;; aperture_science -&gt; &lt;&lt;\"client:\", (prefix_for(aperture_science))/binary, \":orgs\"&gt;&gt;; wayne_ents -&gt; &lt;&lt;\"client:\", (prefix_for(wayne_ents))/binary, \":orgs\"&gt;&gt; end)].good() -&gt; Client = active_user:get_current_client(), RawOrgs = autocomplete_db:members(client_ac_key(Client)), [binary_to_list(Org) || Org &lt;- RawOrgs].client_ac_key(home_client) -&gt; &lt;&lt;\"our:organizations\"&gt;&gt;;client_ac_key(Client) -&gt; Prefix = prefix_for(Client), &lt;&lt;\"client:\", Prefix/binary, \":orgs\"&gt;&gt;.prefix_for(aperture_science) -&gt; &lt;&lt;\"as\"&gt;&gt;;prefix_for(wayne_ents) -&gt; &lt;&lt;\"we\"&gt;&gt;. 避免动态调用 动态调用语法，不能使用xref对代码进行检查。 12345678910111213141516-module(dyn_calls).-export([bad/1, good/1]).bad(Arg) -&gt; Mods = [module_1, module_2, module_3], Fun = my_function, lists:foreach( fun(Mod) -&gt; Mod:Fun(Arg) end, Mods).good(Arg) -&gt; mdoule_1:my_function(Arg), module_2:my_function(Arg), module_3:my_function(Arg). 避免深层嵌套 嵌套级别表示函数中的逻辑深度。 避免if表达式 if在代码中引入了静态布尔逻辑，从而降低了代码的灵活性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344-module(no_if).-export([bad/1, better/1, good/1]).bad(Connection) -&gt; &#123;Transport, Version&#125; = other_place:get_http_params(), if Transport =/= cowboy_spdy, Version =:= 'HTTP/1.1' -&gt; [&#123;&lt;&lt;\"connection\"&gt;&gt;, utils:atom_to_connection(Connection)&#125;]; true -&gt; [] end.better(Connection) -&gt; &#123;Transport, Version&#125; = other_place:get_http_params(), case &#123;Transport, Version&#125; of &#123;cowboy_spdy, 'HTTP/1.1'&#125; -&gt; [&#123;&lt;&lt;\"connection\"&gt;&gt;, utils:atom_to_connection(Connection)&#125;]; &#123;_, _&#125; -&gt; [] end.good(Connection) -&gt; &#123;Transport, Version&#125; = other_place:get_http_params(), connection_headers(Transport, Version, Connection).connection_headers(cowboy_spdy, 'HTTP/1.1', Connection) -&gt; [&#123;&lt;&lt;\"connection\"&gt;&gt;, utils:atom_to_connection(Connection)&#125;];connection_headers(_, _, _) -&gt; []. 避免嵌套try….catch 123456789101112131415161718192021222324252627282930313233343536373839-module(nested_try_catch).-export([bad/0, good1/0, good2/0]).bad() -&gt; try maybe:throw(exception1), try maybe:throw(exception2), \"We are safe!\" catch _:exception2 -&gt; \"Oh, no! Exception #2\" end catch _:exception1 -&gt; \"Bummer! Exception #1\" end.good1() -&gt; try maybe:throw(exception1), maybe:throw(exception2), \"We are safe!\" catch _:exception1 -&gt; \"Bummer! Exception #1\"; _:exception2 -&gt; \"Oh, no! Exception #2\" end.good2() -&gt; try maybe:throw(exception1), a_function:that_deals(with, exception2), \"We are safe!\" catch _:exception1 -&gt; \"Bummer! Exception #1\" end. 模块命名要统一 函数名称 函数名称只能使用小写字符和数字。函数名中单词必须用”_” 变量名称 CameCase必须用于变量。 iolists 尽可能使用 1234567-module(iolists).-export([good/1, bad/1]).bad(Param) -&gt; \"Hello \" ++ binary_to_list(Param) ++ \"! Have a nice day!\".good(Param) -&gt; [\"Hello \", Param, \"! Have a nice day!\"]. 大写宏 宏使代码更难调试。 尽量不要把宏作为模块或者函数名 1234567891011121314-module(macro_mod_names).-define(SERVER, ?MODULE). % Oh, god! Why??-define(TM, another_module).-export([bad/1, good/1]).bad(Arg) -&gt; Parsed = gen_server:call(?SERVER, &#123;parse, Arg&#125;), ?TM:handle(Parsed).good(Arg) -&gt; Parsed = gen_server:call(?MODULE, &#123;parse, Arg&#125;), another_module:handle(Parsed). 记录名称 记录名称只能使用小写字符，记录名称中的单词必须用”_”分隔。同样的规则适用于记录字段名称。 1234567891011-module(record_names).-export([records/0]).-record(badName, &#123;&#125;).-record(bad_field_name, &#123;badFieldName :: any()&#125;).-record('UPPERCASE', &#123;'THIS_IS_BAD' :: any()&#125;).-record(good_name, &#123;good_field_name :: any()&#125;).records() -&gt; [#badName&#123;&#125;, #bad_field_name&#123;&#125;, #'UPPERCASE'&#123;&#125;, #good_name&#123;&#125;]. 不要分享记录 记录不应在多个模块之间共享。如果需要共享表示为记录的对象，请使用opaque导出类型并在模块中提供足够的访问者函数。 123456789101112131415161718192021-module(record_sharing).-include(\"record_sharing.hrl\").-export([bad/0, good/0, good_field/1, good_field/2]).-record(good, &#123;good_field :: string()&#125;).-opaque good() :: #good&#123;&#125;.-export_type([good/0]).-spec good() -&gt; good().good() -&gt; #good&#123;&#125;.-spec good_field(good()) -&gt; string().good_field(#good&#123;&#125; = Good) -&gt; Good#good.good_field.-spec good_field(good(), string()) -&gt; good().good_field(#good&#123;&#125; = Good, Value) -&gt; Good#good&#123;good_field = Value&#125;.-spec bad() -&gt; #bad&#123;&#125;.bad() -&gt; #bad&#123;&#125;.","categories":[{"name":"开发语言","slug":"开发语言","permalink":"http://yoursite.com/categories/开发语言/"}],"tags":[{"name":"erlang","slug":"erlang","permalink":"http://yoursite.com/tags/erlang/"}]},{"title":"erlang异常错误编程样式","slug":"erlang异常错误编程样式","date":"2019-02-23T06:22:53.000Z","updated":"2019-02-23T06:22:53.000Z","comments":true,"path":"2019/02/23/erlang异常错误编程样式/","link":"","permalink":"http://yoursite.com/2019/02/23/erlang异常错误编程样式/","excerpt":"try catch end和catch区别 catch在try catch end引入之前就时erlang语言的一部分了。 异常错误如果发生在catch语句中，就会被转换成一个描述此错误的{‘EXIT’, …}元组。 异常错误编程样式 改进错误信息 1234sqrt(X) when X &lt; 0 -&gt; error(&#123;argument_error, X&#125;);sqrt(X) -&gt; match:sqrt(X).","text":"try catch end和catch区别 catch在try catch end引入之前就时erlang语言的一部分了。 异常错误如果发生在catch语句中，就会被转换成一个描述此错误的{‘EXIT’, …}元组。 异常错误编程样式 改进错误信息 1234sqrt(X) when X &lt; 0 -&gt; error(&#123;argument_error, X&#125;);sqrt(X) -&gt; match:sqrt(X). 经常返回错误时代码 如果函数没有什么“通常的情形”，那么多半返回{ok, Val}或者{error, Reason}，这样迫使所有调用者必须对返回值做什么。一种代码编写： 123456case f(X) of &#123;ok, Val&#125; -&gt; do_some_thine_with(Val); &#123;error, Why&#125; -&gt; %% ...处理错误....end. 两种返回都要处理。 另一种代码编写： 12&#123;ok, Val&#125; = f(X),do_some_thing_with(Val). 这样，如果f(X)返回错误，就会抛出错误。 错误可能有但罕见时的代码 这种情况下，通常要编写能够处理错误的代码。 12345try f(X)catch throw:&#123;thisError, X&#125; -&gt; .... throe:&#123;someOtherError, X&#125; -&gt; ....end f(X) 函数实现： 123456789f(X) -&gt; case ... of ... -&gt; Result; ... -&gt; throw(&#123;thisError,...&#125;); ... -&gt; throw(&#123;someOtherError,...&#125;) end. 捕捉一切可能的异常错误 123456789try Expr catch _:_ ... 匹配处理所有异常end 或者：try Exprcatch _ ... 默认只能处理throw:_ 类型的错误end 事例1234567891011121314151617181920generate_exception(1) -&gt; a;generate_exception(2) -&gt; throw(a);generate_exception(3) -&gt; exit(a);generate_exception(4) -&gt; &#123;'EXIT', a&#125;; %%模拟返回错误generate_exception(5) -&gt; error(a).catcher(N) -&gt; try generate_exception(N) of Val -&gt; &#123;N, normal, Val&#125; catch throw:X -&gt; &#123;N, caught, throw, X&#125;; exit:X -&gt; &#123;N, caught, exited, X&#125;; error:X -&gt; &#123;N, caucaughtgth, error, X&#125; end. demo1() -&gt; [catcher(I) || I &lt;- lists:seq(1,5)]. demo2() -&gt;[&#123;I, (catch generate_exception(I))&#125; || I &lt;- lists:seq(1,5)]. 结果： 12345678910111213141516171819202&gt; demo1().[&#123;1,normal,a&#125;, &#123;2,caught,throw,a&#125;, &#123;3,caught,exited,a&#125;, &#123;4,normal,&#123;'EXIT',a&#125;&#125;, &#123;5,caught,error,a&#125;]3&gt; demo2().[&#123;1,a&#125;, &#123;2,a&#125;, &#123;3,&#123;'EXIT',a&#125;&#125;, &#123;4,&#123;'EXIT',a&#125;&#125;, &#123;5, &#123;'EXIT',&#123;a,[&#123;a,generate_exception,1, [&#123;file,\"a.erl\"&#125;,&#123;line,7&#125;]&#125;, &#123;a,'-demo2/0-lc$^0/1-0-',1,[&#123;file,\"a.erl\"&#125;,&#123;line,19&#125;]&#125;, &#123;a,'-demo2/0-lc$^0/1-0-',1,[&#123;file,\"a.erl\"&#125;,&#123;line,19&#125;]&#125;, &#123;erl_eval,do_apply,6,[&#123;file,\"erl_eval.erl\"&#125;,&#123;line,674&#125;]&#125;, &#123;shell,exprs,7,[&#123;file,\"shell.erl\"&#125;,&#123;line,686&#125;]&#125;, &#123;shell,eval_exprs,7,[&#123;file,\"shell.erl\"&#125;,&#123;line,641&#125;]&#125;, &#123;shell,eval_loop,3,[&#123;file,\"shell.erl\"&#125;,&#123;line,626&#125;]&#125;]&#125;&#125;&#125;] 通过catch捕捉这三种异常返回的结果分别是： throw(Any) -&gt; Term exit(Reason) -&gt; {‘EXIT’,Reason} error(Reason) -&gt; {‘EXIT’,{Reason,erlang:get_stacktrace()}} 使用这三种异常的场景为： exit(Reason): 当想要终止当前进程时，用这个函数。如果这个消息未被捕获，那么系统会向所有与当前进程连接的进程广告{‘EXIT’,Pid,Reason}消息 throw(Any): 用于抛出一个调用者可能会捕获的异常。针对throw，必须为函数添加注释，说明他会抛出这个异常。调用者可以选择：忽略这些异常/对异常进行处理。 error(Reason): 用于抛出那些“崩溃错误“。这种异常应该是调用者不会真正意识到要去处理的那些致命错误。","categories":[{"name":"开发语言","slug":"开发语言","permalink":"http://yoursite.com/categories/开发语言/"}],"tags":[{"name":"erlang异常错误编程样式","slug":"erlang异常错误编程样式","permalink":"http://yoursite.com/tags/erlang异常错误编程样式/"}]},{"title":"rpc知识","slug":"RPC","date":"2019-02-23T06:22:53.000Z","updated":"2019-02-23T06:22:53.000Z","comments":true,"path":"2019/02/23/RPC/","link":"","permalink":"http://yoursite.com/2019/02/23/RPC/","excerpt":"RPC（即Remote Procedure Call，远程过程调用）和HTTP（HyperText Transfer Protocol，超文本传输协议）他们最本质的区别，就是RPC主要工作在TCP协议之上，而HTTP服务主要是工作在HTTP协议之上，我们都知道HTTP协议是在传输层协议TCP之上的，所以效率来看的话，RPC当然是要更胜一筹。","text":"RPC（即Remote Procedure Call，远程过程调用）和HTTP（HyperText Transfer Protocol，超文本传输协议）他们最本质的区别，就是RPC主要工作在TCP协议之上，而HTTP服务主要是工作在HTTP协议之上，我们都知道HTTP协议是在传输层协议TCP之上的，所以效率来看的话，RPC当然是要更胜一筹。 1、RPC服务（1）RPC架构 先说说RPC服务的基本架构吧。一个完整的RPC架构里面包含了四个核心的组件，分别是Client ,Server,Client Stub以及Server Stub，这个Stub大家可以理解为存根。分别说说这几个组件： 1)客户端（Client），服务的调用方。 2)服务端（Server），真正的服务提供者。 3)客户端存根，存放服务端的地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。 4)服务端存根，接收客户端发送过来的消息，将消息解包，并调用本地的方法。 （2）同步调用与异步调用 什么是同步调用？什么是异步调用？同步调用就是客户端等待调用执行完成并返回结果。异步调用就是客户端不等待调用执行完成返回结果，不过依然可以通过回调函数等接收到返回结果的通知。如果客户端并不关心结果，则可以变成一个单向的调用。这个过程有点类似于Java中的callable和runnable接口，我们进行异步执行的时候，如果需要知道执行的结果，就可以使用callable接口，并且可以通过Future类获取到异步执行的结果信息。如果不关心执行的结果，直接使用runnable接口就可以了，因为它不返回结果，当然啦，callable也是可以的，我们不去获取Future就可以了。（3）流行的RPC框架 目前流行的开源RPC框架还是比较多的。下面重点介绍三种： 1）gRPC是Google最近公布的开源软件，基于最新的HTTP2.0协议，并支持常见的众多编程语言。 我们知道HTTP2.0是基于二进制的HTTP协议升级版本，目前各大浏览器都在快马加鞭的加以支持。 这个RPC框架是基于HTTP协议实现的，底层使用到了Netty框架的支持。 2）Thrift是Facebook的一个开源项目，主要是一个跨语言的服务开发框架。它有一个代码生成器来对它所定义的IDL定义文件自动生成服务代码框架。用户只要在其之前进行二次开发就行，对于底层的RPC通讯等都是透明的。不过这个对于用户来说的话需要学习特定领域语言这个特性，还是有一定成本的。 3）Dubbo是阿里集团开源的一个极为出名的RPC框架，在很多互联网公司和企业应用中广泛使用。协议和序列化框架都可以插拔是及其鲜明的特色。同样 的远程接口是基于Java Interface，并且依托于spring框架方便开发。可以方便的打包成单一文件，独立进程运行，和现在的微服务概念一致。2、HTTP服务 （1）HTTP接口 相比RPC，HTTP接口开发也就是我们常说的RESTful风格的服务接口。的确，对于在接口不多、系统与系统交互较少的情况下，解决信息孤岛初期常使用的一种通信手段；优点就是简单、直接、开发方便。利用现成的http协议进行传输。做后台接口开发的时候，需要写一份接口文档，严格地标明输入输出是什么？说清楚每一个接口的请求方法，以及请求参数需要注意的事项等。","categories":[{"name":"协议","slug":"协议","permalink":"http://yoursite.com/categories/协议/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"http://yoursite.com/tags/rpc/"}]},{"title":"VOIP名词","slug":"VOIP名词","date":"2019-02-23T06:22:53.000Z","updated":"2019-02-23T06:22:53.000Z","comments":true,"path":"2019/02/23/VOIP名词/","link":"","permalink":"http://yoursite.com/2019/02/23/VOIP名词/","excerpt":"名词 ASR：自动语音识别(Automatic Speech Recognition) TTS：(Text To Speech,文本转语音) IaaS：Infrastructure-as-a-Service(基础设施即服务) PaaS：Platform-as-a-Service(平台即服务) SaaS：Software-as-a-Service(软件即服务)","text":"名词 ASR：自动语音识别(Automatic Speech Recognition) TTS：(Text To Speech,文本转语音) IaaS：Infrastructure-as-a-Service(基础设施即服务) PaaS：Platform-as-a-Service(平台即服务) SaaS：Software-as-a-Service(软件即服务)","categories":[{"name":"开源框架","slug":"开源框架","permalink":"http://yoursite.com/categories/开源框架/"}],"tags":[{"name":"VOIP","slug":"VOIP","permalink":"http://yoursite.com/tags/VOIP/"}]},{"title":"voip网络核心设备SBC","slug":"Voip网络核心设备-SBC","date":"2019-02-23T06:22:53.000Z","updated":"2019-02-23T06:22:53.000Z","comments":true,"path":"2019/02/23/Voip网络核心设备-SBC/","link":"","permalink":"http://yoursite.com/2019/02/23/Voip网络核心设备-SBC/","excerpt":"Voip网络核心设备-SBCSBC（Session Border Controlle）是目前voip网络中的核心设备，中文意思是会话边界控制器。顾名思义，就是在网络边界处（内网和外网）对会话进行管理的设备。我们提到的会话是指SIP Session。","text":"Voip网络核心设备-SBCSBC（Session Border Controlle）是目前voip网络中的核心设备，中文意思是会话边界控制器。顾名思义，就是在网络边界处（内网和外网）对会话进行管理的设备。我们提到的会话是指SIP Session。 功能SBC提供拓隐藏，呼叫路由管理，防攻击， NAT穿越， QOS， TDM接入， B2BUA，语音编码处理， SIP注册等。 SBC在VOIP网络环境中核心功能包括： SIP消息的规范话。在复杂的环境中，接入的设备终端可能来自不同的厂家，不同的私有协议标准，SBC必须对SIP消息进行规范化处理，确保其他的通信设备可以相互交互。 编码转换。 对NAT处理。 传真和语音检测功能。 具有良好的性能。 部署利用开源平台搭建SBC。openSIPS,kamailio,FreeSwtich。 kamailio + rtpproxy。","categories":[{"name":"开源框架","slug":"开源框架","permalink":"http://yoursite.com/categories/开源框架/"}],"tags":[{"name":"voip","slug":"voip","permalink":"http://yoursite.com/tags/voip/"}]},{"title":"Freeswitch事件","slug":"Freeswitch事件","date":"2019-02-23T06:22:53.000Z","updated":"2019-02-23T06:22:53.000Z","comments":true,"path":"2019/02/23/Freeswitch事件/","link":"","permalink":"http://yoursite.com/2019/02/23/Freeswitch事件/","excerpt":"Freeswitch内核之事件类型 事件 说明3 Channel events 信道事件。3.1 Channel states 信道状态。3.2 CHANNEL_CALLSTATE 信道呼叫状态事件。3.3 CHANNEL_CREATE 创建事件。3.4 CHANNEL_DESTROY 销毁事件。3.5 CHANNEL_STATE 呼叫状态事件。当一个信道切换通话状态时发送。此事件并不包含任何附加信息。","text":"Freeswitch内核之事件类型 事件 说明3 Channel events 信道事件。3.1 Channel states 信道状态。3.2 CHANNEL_CALLSTATE 信道呼叫状态事件。3.3 CHANNEL_CREATE 创建事件。3.4 CHANNEL_DESTROY 销毁事件。3.5 CHANNEL_STATE 呼叫状态事件。当一个信道切换通话状态时发送。此事件并不包含任何附加信息。3.6 CHANNEL_ANSWER 呼叫应答事件。3.7 CHANNEL_HANGUP 挂机事件。3.8 CHANNEL_HANGUP_COMPLETE 挂机完成事件。3.9 CHANNEL_EXECUTE PBX正在执行呼叫事件。3.10 CHANNEL_EXECUTE_COMPLETE 执行完成。3.11 CHANNEL_BRIDGE 一个呼叫两个端点之间的桥接事件。3.12 CHANNEL_UNBRIDGE 停用桥接事件。3.13 CHANNEL_PROGRESS 进度事件，外呼时对方提醒。或者入呼时提醒。3.14 CHANNEL_PROGRESS_MEDIA 媒体进度事件，外呼时对方提醒。或者入呼时提醒。3.15 CHANNEL_OUTGOING 创建一个外呼事件。3.16 CHANNEL_PARK 一个呼叫被挂起(停放)在PBX中。3.17 CHANNEL_UNPARK 一个呼叫被取消挂起(停放)在PBX中。3.18 CHANNEL_APPLICATION 信道产生的应用程序就是事件application=event一般用来捕获呼转3.19 CHANNEL_HOLD 信道保持，使用uuid_hold或者接收SDP的readonly3.20 CHANNEL_UNHOLD 触发后uuid_hold关闭或者接收到INVITE SDP= SendRecv的3.21 CHANNEL_ORIGINATE 信道发起事件，触发完成发起（或桥）。3.22 CHANNEL_UUID uuid事件表示唯一的ID通道已经改变。原来的ID将被报告的旧唯一ID。此事件会发生，当您使用参数origination_uuid时发出命令发起/桥。4 System events4.1 SHUTDOWN 设置以启动的FreeSWITCH的关机顺序。4.2 MODULE_LOAD 模块加载4.3 MODULE_UNLOAD 模块卸载4.4 RELOADXML 重新加载已经配置的XML4.5 NOTIFY 通知4.6 SEND_MESSAGE 发送信息4.7 RECV_MESSAGE 接收信息4.8 REQUEST_PARAMS 请求参数4.9 CHANNEL_DATA 信道数据4.10 GENERAL 总体4.11 COMMAND 命令4.12 SESSION_HEARTBEAT session心跳4.13 CLIENT_DISCONNECTED 客户端断开4.14 SERVER_DISCONNECTED 服务器断开4.15 SEND_INFO 发送信息4.16 RECV_INFO 接收信息4.17 CALL_SECURE 保密呼叫4.18 NAT nat4.19 RECORD_START 开始记录4.20 RECORD_STOP 停止记录4.21 PLAYBACK_START 开始播放4.22 PLAYBACK_STOP 停止播放4.23 CALL_UPDATE 更新呼叫 https://blog.csdn.net/hry2015/article/details/78347467","categories":[{"name":"开源框架","slug":"开源框架","permalink":"http://yoursite.com/categories/开源框架/"}],"tags":[{"name":"Freeswitch","slug":"Freeswitch","permalink":"http://yoursite.com/tags/Freeswitch/"}]},{"title":"IVR知识","slug":"IVR知识","date":"2019-02-20T12:04:23.000Z","updated":"2019-02-20T12:04:23.000Z","comments":true,"path":"2019/02/20/IVR知识/","link":"","permalink":"http://yoursite.com/2019/02/20/IVR知识/","excerpt":"自动外呼用户下单后，外卖平台自动拨打商家电话，商家接通电话后播放ivr语音。 简单流程：播放订单信息后挂断。 复杂流程：商家根据播放语音选择按键，进入下一级ivr流程。","text":"自动外呼用户下单后，外卖平台自动拨打商家电话，商家接通电话后播放ivr语音。 简单流程：播放订单信息后挂断。 复杂流程：商家根据播放语音选择按键，进入下一级ivr流程。","categories":[{"name":"CTI呼叫中心","slug":"CTI呼叫中心","permalink":"http://yoursite.com/categories/CTI呼叫中心/"}],"tags":[{"name":"IVR知识","slug":"IVR知识","permalink":"http://yoursite.com/tags/IVR知识/"}]},{"title":"redis集群","slug":"redis集群","date":"2019-02-20T08:28:10.000Z","updated":"2019-02-20T11:59:05.899Z","comments":true,"path":"2019/02/20/redis集群/","link":"","permalink":"http://yoursite.com/2019/02/20/redis集群/","excerpt":"redis 单点、redis主从、redis哨兵sentinel、redis集群cluster配置搭建。","text":"redis 单点、redis主从、redis哨兵sentinel、redis集群cluster配置搭建。 redis单点编辑redis.conf 12port 6379daemonize yes 指定后台运行 配置说明： 12345678910111213141516171819202122232425daemonize：如需要在后台运行，把该项的值改为yespdifile：把pid文件放在/var/run/redis.pid，可以配置到其他地址bind：指定redis只接收来自该IP的请求，如果不设置，那么将处理所有请求，在生产环节中最好设置该项port：监听端口，默认为6379timeout：设置客户端连接时的超时时间，单位为秒loglevel：等级分为4级，debug，revbose，notice和warning。生产环境下一般开启noticelogfile：配置log文件地址，默认使用标准输出，即打印在命令行终端的端口上database：设置数据库的个数，默认使用的数据库是0save：设置redis进行数据库镜像的频率rdbcompression：在进行镜像备份时，是否进行压缩dbfilename：镜像备份文件的文件名dir：数据库镜像备份的文件放置的路径slaveof：设置该数据库为其他数据库的从数据库masterauth：当主数据库连接需要密码验证时，在这里设定requirepass：设置客户端连接后进行任何其他指定前需要使用的密码maxclients：限制同时连接的客户端数量maxmemory：设置redis能够使用的最大内存appendonly：开启appendonly模式后，redis会把每一次所接收到的写操作都追加到appendonly.aof文件中，当redis重新启动时，会从该文件恢复出之前的状态appendfsync：设置appendonly.aof文件进行同步的频率vm_enabled：是否开启虚拟内存支持vm_swap_file：设置虚拟内存的交换文件的路径vm_max_momery：设置开启虚拟内存后，redis将使用的最大物理内存的大小，默认为0vm_page_size：设置虚拟内存页的大小vm_pages：设置交换文件的总的page数量vm_max_thrrads：设置vm IO同时使用的线程数量 redis主从123456789mkdir redis-master-slavecp path/to/redis/conf/redis.conf path/to/redis-master-slave master.confcp path/to/redis/conf/redis.conf path/to/redis-master-slave slave.conf## master.confport 6379## slave.confport 6380slaveof 127.0.0.1 6379 启动主从redis，打开两个命令窗口执行info 1234567# Replicationrole:master# Replicationrole:slavemaster_host:127.0.0.1master_port:6379 主节点set数据后，可以在从节点get数据，但是在从节点不可以set 哨兵sentinel上面我们介绍了主从，从库作为一个“傀儡”，可以在需要的时候“顶上来”，”接盘“。我们配置的主从是为了”有备无患“，在主redis挂了之后，可以立马切换到从redis上，可能只需要花几分钟的时间，但是仍然是需要人为操作。这个时候redis sentinel 就派上用场了。sentinel 通常翻译成哨兵，就是放哨的，这里它就是用来监控主从节点的健康情况。客户端连接redis主从的时候，先连接 sentinel，sentinel会告诉客户端主redis的地址是多少，然后客户端连接上redis并进行后续的操作。当主节点挂掉的时候，客户端就得不到连接了因而报错了，客户端重新想sentinel询问主master的地址，然后客户端得到了新选举出来的主redis，然后又可以愉快的操作了。 为了说明sentinel的用处，我们做个试验。配置3个redis（1主2从），1个哨兵。步骤如下： 123456mkdir redis-sentinelcd redis-sentinelcp redis/path/conf/redis.conf path/to/redis-sentinel/redis01.confcp redis/path/conf/redis.conf path/to/redis-sentinel/redis02.confcp redis/path/conf/redis.conf path/to/redis-sentinel/redis03.conftouch sentinel.conf 上我们创建了 3个redis配置文件，1个哨兵配置文件。我们将 redis01设置为master,将redis02，redis03设置为slave。 123456789101112131415vim redis01.confport 63791vim redis02.confport 63792slaveof 127.0.0.1 63791vim redis03.confport 63793slaveof 127.0.0.1 63791vim sentinel.confdaemonize yesport 26379sentinel monitor mymaster 127.0.0.1 63791 1 哨兵配置： 123456789101112port 26379protected-mode nopidfile \"/usr/local/redis/var/redis-sentinel.pid\"dir \"/usr/local/redis/data/sentinel\"daemonize yeslogfile \"/usr/local/redis/var/redis-sentinel.log\"sentinel monitor mymaster 127.0.0.1 63791 1sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 18000sentinel auth-pass mymaster adminsentinel failover-timeout mymaster 18000sentinel auth-pass mymaster admin mymaster 为主节点名字，可以随便取，后面程序里边连接的时候要用到 127.0.0.1 63793 为主节点的 ip,port 1 后面的数字 1 表示选举主节点的时候，投票数。1表示有一个sentinel同意即可升级为master。 主节点宕机模拟： 12345678初始情况下，1主2从# +monitor master mymaster 127.0.0.1 63791 quorum 1* +slave slave 127.0.0.1:63792 127.0.0.1 63792 @ mymaster 127.0.0.1 63791* +slave slave 127.0.0.1:63793 127.0.0.1 63793 @ mymaster 127.0.0.1 63791发现主挂了，准备 故障转移# +try-failover master mymaster 127.0.0.1 63791将主切换到了 63793 即redis03 # +switch-master mymaster 127.0.0.1 63791 127.0.0.1 63793 切换异常：30367:X 17 Oct 13:24:11.578 # -failover-abort-not-elected master mymaster 127.0.0.1 63793 解决：如果redis.conf配置中配置了 protected-mode yes bind 192.168.98.136 则需要在sentinel 配置文件加上protected-mode no 否则在sentinel 配置文件加上 protected-mode yes bind 192.168.98.136 redis cluster 单个redis并发有限 单个redis内存有限，内存太大导致rdb文件过大，同步回复数据会很慢。 所有，我们需要redis cluster 即redis集群。 Redis 集群是一个提供在多个Redis间节点间共享数据的程序集。 Redis 集群并不支持处理多个keys的命令,因为这需要在不同的节点间移动数据,从而达不到像Redis那样的性能,在高负载的情况下可能会导致不可预料的错误. Redis 集群通过分区来提供一定程度的可用性,在实际环境中当某个节点宕机或者不可达的情况下继续处理命令. Redis 集群的优势: 自动分割数据到不同的节点上。 整个集群的部分节点失败或者不可达的情况下能够继续处理命令。 因为最小的redis集群，需要至少3个主节点，既然有3个主节点，而一个主节点搭配至少一个从节点，因此至少得6台redis。 创建redis集群： 1redis-5.0.3/src/redis-cli --cluster create 127.0.0.1:6371 127.0.0.1:6372 127.0.0.1:6373 127.0.0.1:6374 127.0.0.1:6375 127.0.0.1:6376 --cluster-replicas 1 集群管理界面：Relumin","categories":[{"name":"开源框架","slug":"开源框架","permalink":"http://yoursite.com/categories/开源框架/"}],"tags":[{"name":"redis集群","slug":"redis集群","permalink":"http://yoursite.com/tags/redis集群/"}]},{"title":"rabbitmq集群","slug":"rabbitmq集群","date":"2019-02-20T06:38:10.000Z","updated":"2019-02-20T11:48:38.157Z","comments":true,"path":"2019/02/20/rabbitmq集群/","link":"","permalink":"http://yoursite.com/2019/02/20/rabbitmq集群/","excerpt":"集群RabbitMQ集群中可以共享user，virtualhosts，queues，exchanges等。但message只会在创建的节点上传输。当message进入A节点的queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。RABBITMQ的集群节点包括内存节点、磁盘节点。内存节点的元数据仅放在内存中，性能比磁盘节点会有所提升。不过，如果在投递message时，打开了message的持久化，那么内存节点的性能只能体现在资源管理上，比如增加或删除队列（queue），虚拟主机（vrtual hosts），交换机（exchange）等，发送和接受message速度同磁盘节点一样。一个集群至少要有一个磁盘节点。","text":"集群RabbitMQ集群中可以共享user，virtualhosts，queues，exchanges等。但message只会在创建的节点上传输。当message进入A节点的queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。RABBITMQ的集群节点包括内存节点、磁盘节点。内存节点的元数据仅放在内存中，性能比磁盘节点会有所提升。不过，如果在投递message时，打开了message的持久化，那么内存节点的性能只能体现在资源管理上，比如增加或删除队列（queue），虚拟主机（vrtual hosts），交换机（exchange）等，发送和接受message速度同磁盘节点一样。一个集群至少要有一个磁盘节点。 普通集群 cookie同步 同步/var/lib/rabbitmq/erlang.cookie，本文件默认权限400。 加入集群 123rabbitmqctl stop_apprabbitmqctl join_cluster rabbit@tabbitmq1rabbitmqctl start_app 查看集群信息 1rabbitmqctl cluster_status 更改节点属性 123rabbitmqctl stop_apprabbitmqctl change_cluster_node_type disc/ramrabbitmqctl start_app 节点退出集群 123456退出节点服务执行：rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_app集群主节点执行：rabbitmqctl forget_cluster_node rabbit@rabbitmq2 rabbitmq集群重启 集群重启时，最后一个挂掉的节点应该第一个重启，如果因特殊原因（比如同时断电），而不知道哪个节点最后一个挂掉。可用以下方法重启： 123456rabbitmqctl force_bootservice rabbitmq-server start在其他节点上执行service rabbitmq-server start查看cluster状态是否正常（要在所有节点上查询）。rabbitmqctl cluster_status 如果有节点没加入集群，可以先退出集群，然后再重新加入集群。上述方法不适合内存节点重启，内存节点重启的时候是会去磁盘节点同步数据，如果磁盘节点没起来，内存节点一直失败。 镜像队列镜像队列可以同步queue和message，当主queue挂掉，从queue中会有一个变为主queue来接替工作。 镜像队列是基于普通的集群模式的,所以你还是得先配置普通集群,然后才能设置镜像队列。 镜像队列设置后，会分一个主节点和多个从节点，如果主节点宕机，从节点会有一个选为主节点，原先的主节点起来后会变为从节点。 queue和message虽然会存在所有镜像队列中，但客户端读取时不论物理面连接的主节点还是从节点，都是从主节点读取数据，然后主节点再将queue和message的状态同步给从节点，因此多个客户端连接不同的镜像队列不会产生同一message被多次接受的情况。 #rabbitmqctl set_policy ha-all “hello” ‘{“ha-mode”:”all”}’ ha-all 是同步模式，指同步给所有节点，还有另外两种模式ha-exactly表示在指定个数的节点上进行镜像，节点的个数由ha-params指定，ha-nodes表示在指定的节点上进行镜像，节点名称通过ha-params指定； hello 是同步的队列名，可以用正则表达式匹配； {“ha-mode”:”all”} 表示同步给所有，同步模式的不同，此参数也不同。","categories":[{"name":"开源框架","slug":"开源框架","permalink":"http://yoursite.com/categories/开源框架/"}],"tags":[{"name":"rabbitmq集群","slug":"rabbitmq集群","permalink":"http://yoursite.com/tags/rabbitmq集群/"}]},{"title":"Intellij IDEA使用","slug":"IntellijIDEA使用","date":"2019-02-13T09:27:28.000Z","updated":"2019-02-13T09:27:28.000Z","comments":true,"path":"2019/02/13/IntellijIDEA使用/","link":"","permalink":"http://yoursite.com/2019/02/13/IntellijIDEA使用/","excerpt":"","text":"关闭自动更新 Intellij IDEA -&gt; Preferences -&gt; Appearance &amp; Behavior -&gt; System Settings -&gt; Updates 下取消 Automatically check updates for勾选 代码编辑器主题风格 Intellij IDEA -&gt; Preferences -&gt; Editor -&gt; Colors &amp; Fonts -&gt; Font 1234Scheme: DarculaShow only monospaced fonts 设置第一字体，Monaco 不支持中文 Primary font:Monaco Size:20 Line spacing:1.0Secondary font：YaHei Consolas Hybrid 设置第二字体 文件编码 File -&gt; Settings -&gt; Editor -&gt; File Encodings 1234Global Encoding:UTF-8Projectt Encoding:UTF-8Default encoding for properties files:UTF-8勾选上Transparent native-to-ascii conversion 类和方法注视模版 在File -&gt; Settings -&gt; Editor -&gt; File and Code Templates 编码缩进 Intellij IDEA -&gt; Preferences -&gt; Editor -&gt; Code Style -&gt; Erlang Use tab character 不要勾选，然后indent设置为4，代表按一个tab为4个空格，并且自动整理格式也是4个空格一缩进。 123Tab size: 4 Indent: 4Continuation indent: 8 如果要对多个文件进行转换，可以在文件夹上面按右键，然后点击Reformat Code或者选中文件夹按快捷键ctrl+alt+L对多个快捷键整理。","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://yoursite.com/categories/开发工具/"}],"tags":[{"name":"idea","slug":"idea","permalink":"http://yoursite.com/tags/idea/"}]},{"title":"java安装","slug":"java安装","date":"2019-02-13T09:23:39.000Z","updated":"2019-02-20T06:33:05.355Z","comments":true,"path":"2019/02/13/java安装/","link":"","permalink":"http://yoursite.com/2019/02/13/java安装/","excerpt":"java 1.8 安装 yum install yum install java-1.8.0-openjdk-devel.x86_64 java 环境变量 CLASSPATH中的tools.jar主要包含一些工具，如javac（将.java编译为.class）、javadoc（根据java源文件以html格式生成API文档）、javap（反汇编.class文件）等； 1234PATH=$PATH:$HOME/binJAVA_HOME=/usr/lib/jvm/java-1.8.0CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jarPATH=$JAVA_HOME/bin:$HOME/bin:$HOME/.local/bin:$PATH","text":"java 1.8 安装 yum install yum install java-1.8.0-openjdk-devel.x86_64 java 环境变量 CLASSPATH中的tools.jar主要包含一些工具，如javac（将.java编译为.class）、javadoc（根据java源文件以html格式生成API文档）、javap（反汇编.class文件）等； 1234PATH=$PATH:$HOME/binJAVA_HOME=/usr/lib/jvm/java-1.8.0CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jarPATH=$JAVA_HOME/bin:$HOME/bin:$HOME/.local/bin:$PATH java 1.8 安装 yum install yum install java-1.8.0-openjdk-devel.x86_64 java 环境变量 CLASSPATH中的tools.jar主要包含一些工具，如javac（将.java编译为.class）、javadoc（根据java源文件以html格式生成API文档）、javap（反汇编.class文件）等； 1234PATH=$PATH:$HOME/binJAVA_HOME=/usr/lib/jvm/java-1.8.0CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jarPATH=$JAVA_HOME/bin:$HOME/bin:$HOME/.local/bin:$PATH java 安装目录信息 dt.jar中包含了关于swing的控件对应的图标和BeanInfo.class 123456789101112/usr/lib/jvm-exports/java/usr/lib/java/usr/lib/jvm/java/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.191.b12-1.el7_6.x86_64/jre/bin/java/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.191.b12-1.el7_6.x86_64/bin/java/usr/share/java/usr/bin/java/var/lib/alternatives/java/etc/pki/java/etc/pki/ca-trust/extracted/java/etc/java/etc/alternatives/java","categories":[{"name":"开发语言","slug":"开发语言","permalink":"http://yoursite.com/categories/开发语言/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"rabbitmq知识","slug":"rabbitmq知识","date":"2019-02-13T09:23:39.000Z","updated":"2019-02-20T09:12:56.932Z","comments":true,"path":"2019/02/13/rabbitmq知识/","link":"","permalink":"http://yoursite.com/2019/02/13/rabbitmq知识/","excerpt":"RabbitMQ简介RabbitMQ是实现AMQP（高级消息队列协议）的消息中间件的一种，最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。RabbitMQ主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。 AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。","text":"RabbitMQ简介RabbitMQ是实现AMQP（高级消息队列协议）的消息中间件的一种，最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。RabbitMQ主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。 AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 交换机(Exchange)RabbitMQ常用的Exchange Type有fanout、direct、topic、headers这四种（AMQP规范里还提到两种Exchange Type，分别为system与自定义，这里不予以描述） fanout 转发消息到所有绑定队列。 direct 把消息路由到那些binding key与routing key完全匹配的Queue中。 headers headers类型的Exchange不依赖于routing key与binding key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。 在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对；如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。 topic topic类型的Exchange在匹配规则上进行了扩展。 routing key为一个句点号“. ”分隔的字符串（我们将被句点号“. ”分隔开的每一段独立的字符串称为一个单词），如“stock.usd.nyse”、“nyse.vmw”、“quick.orange.rabbit”。 binding key与routing key一样也是句点号“. ”分隔的字符串。 binding key中可以存在两种特殊字符“”与“#”，用于做模糊匹配，其中“”用于匹配一个单词，“#”用于匹配多个单词（可以是零个）。 RabbitMQ RPC RabbitMQ 中实现RPC的机制是： 客户端发送请求（消息）时，在消息的属性（MessageProperties，在AMQP协议中定义了14中properties，这些属性会随着消息一起发送）中设置两个值replyTo（一个Queue名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue中）和correlationId（此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败） 服务器端收到消息并处理 服务器端处理完消息后，将生成一条应答消息到replyTo指定的Queue，同时带上correlationId属性 客户端之前已订阅replyTo指定的Queue，从中收到服务器的应答消息后，根据其中的correlationId属性分析哪条请求被执行了，根据执行结果进行后续业务处理 RabbitMQ 选型和对比1.从社区活跃度 按照目前网络上的资料，RabbitMQ、activeM、ZeroMQ三者中，综合来看，RabbitMQ是首选。 2.持久化消息比较 ZeroMq不支持，ActiveMq和RabbitMq都支持。持久化消息主要是指我们机器在不可抗力因素等情况下挂掉了，消息不会丢失的机制。 3.综合技术实现 可靠性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统等等。 RabbitMq/Kafka最好，ActiveMq次之，ZeroMq最差。当然ZeroMq也可以做到，不过自己必须手动写代码实现，代码量不小。尤其是可靠性中的：持久性、投递确认、发布者证实和高可用性。 4.高并发 毋庸置疑，RabbitMQ最高，原因是它的实现语言是天生具备高并发高可用的erlang语言。 5.比较关注的比较，RabbitMQ和 Kafka RabbitMq比Kafka成熟，在可用性上，稳定性上，可靠性上， RabbitMq 胜于 Kafka （理论上）。 另外，Kafka的定位主要在日志等方面， 因为Kafka设计的初衷就是处理日志的，可以看做是一个日志（消息）系统一个重要组件，针对性很强，所以 如果业务方面还是建议选择RabbitMq。 RabbitMQ Erlang ClientAmqp Erlang Client","categories":[{"name":"开源框架","slug":"开源框架","permalink":"http://yoursite.com/categories/开源框架/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"}]},{"title":"erlang知识点记录","slug":"erlang知识点记录","date":"2019-01-08T06:22:53.000Z","updated":"2019-01-08T06:22:53.000Z","comments":true,"path":"2019/01/08/erlang知识点记录/","link":"","permalink":"http://yoursite.com/2019/01/08/erlang知识点记录/","excerpt":"gen_server:cast和erlang:send()都可以向指定进程发送消息，两者有什么区别？ gen_server:cast 内部调用erlang:send使用noconnect 123456case catch erlang:send(Dest, Msg, [noconnect]) of noconnect -&gt; spawn(erlang, send, [Dest,Msg]); Other -&gt; Other end. 12345-spec erlang:send(Dest, Msg, Options) -&gt; Res when Dest :: dst(), Msg :: term(), Options :: [nosuspend | noconnect], Res :: ok | nosuspend | noconnect. nosuspend：遇到会挂起进程时不挂起进程，直接返回nosuspend noconnect：遇到远程节点没有连接时不自动连接发送消息，直接返回noconnect","text":"gen_server:cast和erlang:send()都可以向指定进程发送消息，两者有什么区别？ gen_server:cast 内部调用erlang:send使用noconnect 123456case catch erlang:send(Dest, Msg, [noconnect]) of noconnect -&gt; spawn(erlang, send, [Dest,Msg]); Other -&gt; Other end. 12345-spec erlang:send(Dest, Msg, Options) -&gt; Res when Dest :: dst(), Msg :: term(), Options :: [nosuspend | noconnect], Res :: ok | nosuspend | noconnect. nosuspend：遇到会挂起进程时不挂起进程，直接返回nosuspend noconnect：遇到远程节点没有连接时不自动连接发送消息，直接返回noconnect gen_server:call rpc:call和gen_server:call 区别？ rpc模块本身就是gen_server进程，随kernel模块启动，rpc进程启动时通过local注册一个rex的名字。 rpc:call内部调用gen_server:call({Name,Node},Request)，Name是rex，所以说rpc:call是调用远程节点的rex进程做事情，而gen_server:call可以调用任意进程做事情。 erlang:now()和os:timestamp()区别？ erlang:now()获取erlang虚拟机时间，os:timestamp()获取操作系统时间，对于erlang:start_time函数如果调快系统时间，此定时不会提前收到消息。因为erlang:start_time内部使用erlang虚拟机时间。 erlang:send_after和erlang:start_time区别？ 主要是TimerRef，超时消息进入邮箱时，start_time函数的消息携带了TimeRef标识。 ref数据类型 Erlang 虚拟机会创建一个新的 ref。由于全局当前 ref 值是用多个变量表示的，所以 make_ref() 会通过一个自旋锁保护对这些变量的操作，递增全局 ref 的值，然后根据新的 ref 值创建新的 ref 对象并返回对应的 Eterm。递增操作针对 word 0 递增，如果 word 0 超过了218218，则进位到 word 1，word 1 归零的话则进位到 word 2。 我们打印 ref 的时候，得到的是类似 #Ref&lt;0.0.0.2055&gt; 这样的输出，通过 3 个句点将输出结果分为 4 段。第 1 段，和 pid 和 port 的第一段是一样的，表示节点，在本地节点总是为 0，后面 3 段分别为上面的 word 2、1 和 0。所以 ref 较少的时候前面几段都为 0。 ets表 123456789101112-spec new(Name, Options) -&gt; tid() | atom() when Name :: atom(), Options :: [Option], Option :: Type | Access | named_table | &#123;keypos,Pos&#125; | &#123;heir, Pid :: pid(), HeirData&#125; | &#123;heir, none&#125; | Tweaks, Type :: type(), Access :: access(), Tweaks :: &#123;write_concurrency, boolean()&#125; | &#123;read_concurrency, boolean()&#125; | compressed, Pos :: pos_integer(), HeirData :: term(). write_concurrency、read_concurrency是用来提升读写性能的，代价是额外的内存。并不是支持读和写的并发控制的，因为ets本身的读写操作就是原子的。通常来说，ets写数据时整张表是锁定的，其他进程不能进行读写直到前面的操作完成。并发写可以改变这个情况，同一个表中的不同记录可以被多个进程并发读写。有了这个参数，使得ets写记录时表读写锁变成了读锁，就是说，只要不是同一条记录，还可以继续往这个ets表写入数据，提高了并发写效率。但并发写也有弊端，降低数据连续写入的效率和性能。如果有且只有一个进程在读写数据，将会带来一定的开销。而测试发现这个开销比较小，可以忽略。而且，只有一个进程在读写数据的场合比较小。 Pid &lt;A,B,C&gt; A对应节点信息（0代表本地节点，其他数字代表远程节点） B低15字节代表进程表索引 C16～18字节代表进程唯一标识 erlang:dbg、trace、火焰图 receive的理解 receive会检查遍历进程的邮箱一次，如果匹配到条件，就执行条件后的代码，并去掉邮箱中对应消息，停止匹配过程。等待下一条消息到达时触发再次匹配逻辑。","categories":[{"name":"开发语言","slug":"开发语言","permalink":"http://yoursite.com/categories/开发语言/"}],"tags":[{"name":"erlang","slug":"erlang","permalink":"http://yoursite.com/tags/erlang/"}]},{"title":"vimdiff","slug":"vimdiff","date":"2019-01-08T06:22:53.000Z","updated":"2019-01-08T06:22:53.000Z","comments":true,"path":"2019/01/08/vimdiff/","link":"","permalink":"http://yoursite.com/2019/01/08/vimdiff/","excerpt":"##实用的vim下比较两个文件命令： 1、 vimdiff file1 file2终端下输入该命令进入vim，垂直分隔窗口进行比较 2、 vimdiff -o file1 file2水平分隔窗口进行比较 3、 ctrl+w (j,k,h,l)上下左右切换光标所在的窗口（括号中表示可以是其中之一，按下ctrl+w，放开ctrl再按j,k,h,l） 4、 ctrl+w (J,K,H,L)上下左右移动光标所在窗口的位置","text":"##实用的vim下比较两个文件命令： 1、 vimdiff file1 file2终端下输入该命令进入vim，垂直分隔窗口进行比较 2、 vimdiff -o file1 file2水平分隔窗口进行比较 3、 ctrl+w (j,k,h,l)上下左右切换光标所在的窗口（括号中表示可以是其中之一，按下ctrl+w，放开ctrl再按j,k,h,l） 4、 ctrl+w (J,K,H,L)上下左右移动光标所在窗口的位置 5、 zo 和 zc打开折叠区 和 关闭折叠区 6、 ]c 和 [c将光标移动到下一个不同区 和 上一个不同区 7、 do 和 dp将光标所在不同区域同步为另一个文件该位置的内容 和 将光标所在不同区域内容同步到另一个文件该位置 8、 :diffu[!]vim下更新当前比较窗口，比较状态下修改文件后，可调用该命令[中括号不为命令部分，如果加!表示如果外部修改了文件，则重新加载比较] 9、 :diffo[!]vim下关闭当前窗口比较状态，如果加!则关闭所有窗口的比较状态 10、:diffs file1vim下加入file1和当前光标所在窗口进行比较，水平分隔窗口 11、:vert diffs file1vim下加入file1和当前光标所在窗口进行比较，垂直分隔窗口 12、:difftvim下将光标所在窗口变为比较窗口 ##其它技巧： 1、 diff -u file1 file2 &gt; file3终端下输入该命令，可以将file1和file2的比较结果输出到file3中，-u 表示以合并格式比较，-c 为上下文格式，不加为一般格式","categories":[{"name":"系统","slug":"系统","permalink":"http://yoursite.com/categories/系统/"}],"tags":[{"name":"linux-vimdiff","slug":"linux-vimdiff","permalink":"http://yoursite.com/tags/linux-vimdiff/"}]},{"title":"sysctl.conf调整","slug":"linux-sysctl调整","date":"2019-01-08T06:22:53.000Z","updated":"2019-01-08T06:22:53.000Z","comments":true,"path":"2019/01/08/linux-sysctl调整/","link":"","permalink":"http://yoursite.com/2019/01/08/linux-sysctl调整/","excerpt":"设置tcp参数一定要小心谨慎,轻易不要更改线上环境。 123456et.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_fin_timeout = 30 net.ipv4.tcp_keepalive_time = 1800 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_syncookies = 1 www.2cto.com 执行 /sbin/sysctl -p 让参数生效。","text":"设置tcp参数一定要小心谨慎,轻易不要更改线上环境。 123456et.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_fin_timeout = 30 net.ipv4.tcp_keepalive_time = 1800 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_syncookies = 1 www.2cto.com 执行 /sbin/sysctl -p 让参数生效。 大量TIME_WAIT问题 根据TCP协议定义的3次握手断开连接规定,发起socket主动关闭的一方 socket将进入TIME_WAIT状态,TIME_WAIT状态将持续2个MSL(Max Segment Lifetime),在Windows下默认为4分钟,即240秒,TIME_WAIT状态下的socket不能被回收使用. 具体现象是对于一个处理大量短连接的服务器,如果是由服务器主动关闭客户端的连接,将导致服务器端存在大量的处于TIME_WAIT状态的socket, 甚至比处于Established状态下的socket多的多,严重影响服务器的处理能力,甚至耗尽可用的socket,停止服务. TIME_WAIT是TCP协议用以保证被重新分配的socket不会受到之前残留的延迟重发报文影响的机制,是必要的逻辑保证. 解决方案： net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭； net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭； net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。 net.ipv4.tcp_fin_timeout 修改系統默认的 TIMEOUT 时间。 参数说明 tcp_syn_retries ：INTEGER 默认值是5 对于一个新建连接，内核要发送多少个 SYN 连接请求才决定放弃。不应该大于255，默认值是5，对应于180秒左右时间。(对于大负载而物理通信良好的网络而言,这个值偏高,可修改为2.这个值仅仅是针对对外的连接,对进来的连接,是由tcp_retries1 决定的) tcp_synack_retries ：INTEGER 默认值是5 对于远端的连接请求SYN，内核会发送SYN ＋ ACK数据报，以确认收到上一个 SYN连接请求包。这是所谓的三次握手( threeway handshake)机制的第二个步骤。这里决定内核在放弃连接之前所送出的 SYN+ACK 数目。不应该大于255，默认值是5，对应于180秒左右时间。(可以根据上面的tcp_syn_retries来决定这个值) tcp_keepalive_time ：INTEGER 默认值是7200(2小时) 当keepalive打开的情况下，TCP发送keepalive消息的频率。(由于目前网络攻击等因素,造成了利用这个进行的攻击很频繁,曾经也有cu的朋友提到过,说如果2边建立了连接,然后不发送任何数据或者rst/fin消息,那么持续的时间是不是就是2小时,空连接攻击?tcp_keepalive_time就是预防此情形的.我个人在做nat服务的时候的修改值为1800秒) tcp_keepalive_probes：INTEGER 默认值是9 TCP发送keepalive探测以确定该连接已经断开的次数。(注意:保持连接仅在SO_KEEPALIVE套接字选项被打开是才发送.次数默认不需要修改,当然根据情形也可以适当地缩短此值.设置为5比较合适) tcp_keepalive_intvl：INTEGER 默认值为75 探测消息发送的频率，乘以tcp_keepalive_probes就得到对于从开始探测以来没有响应的连接杀除的时间。默认值为75秒，也就是没有活动的连接将在大约11分钟以后将被丢弃。(对于普通应用来说,这个值有一些偏大,可以根据需要改小.特别是web类服务器需要改小该值,15是个比较合适的值) tcp_retries1 ：INTEGER 默认值是3 放弃回应一个TCP连接请求前﹐需要进行多少次重试。RFC 规定最低的数值是3﹐这也是默认值﹐根据RTO的值大约在3秒 - 8分钟之间。(注意:这个值同时还决定进入的syn连接) tcp_retries2 ：INTEGER 默认值为15 在丢弃激活(已建立通讯状况)的TCP连接之前﹐需要进行多少次重试。默认值为15，根据RTO的值来决定，相当于13-30分钟(RFC1122规定，必须大于100秒).(这个值根据目前的网络设置,可以适当地改小,我的网络内修改为了5) tcp_orphan_retries ：INTEGER 默认值是7 在近端丢弃TCP连接之前﹐要进行多少次重试。默认值是7个﹐相当于 50秒 - 16分钟﹐视 RTO 而定。如果您的系统是负载很大的web服务器﹐那么也许需要降低该值﹐这类 sockets 可能会耗费大量的资源。另外参的考tcp_max_orphans 。(事实上做NAT的时候,降低该值也是好处显著的,我本人的网络环境中降低该值为3) tcp_fin_timeout ：INTEGER 默认值是 60 对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。默认值为 60 秒。 过去在2.2版本的内核中是 180 秒。您可以设置该值﹐但需要注意﹐如果您的机器为负载很重的web服务器﹐您可能要冒内存被大量无效数据报填满的风险﹐FIN-WAIT-2 sockets 的危险性低于 FIN-WAIT-1 ﹐因为它们最多只吃 1.5K 的内存﹐但是它们存在时间更长。另外参考 tcp_max_orphans。(事实上做NAT的时候,降低该值也是好处显著的,我本人的网络环境中降低该值为30) tcp_max_tw_buckets ：INTEGER 默认值是180000 系统在同时所处理的最大 timewait sockets 数目。如果超过此数的话﹐time-wait socket 会被立即砍除并且显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐千万不要人为的降低这个限制﹐不过﹐如果网络条件需要比默认值更多﹐则可以提高它(或许还要增加内存)。(事实上做NAT的时候最好可以适当地增加该值) tcp_tw_recycle ：BOOLEAN 默认值是0 打开快速 TIME-WAIT sockets 回收。除非得到技术专家的建议或要求﹐请不要随意修改这个值。(做NAT的时候，建议打开它) tcp_tw_reuse：BOOLEAN 默认值是0 该文件表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接(这个对快速重启动某些服务,而启动后提示端口已经被使用的情形非常有帮助) tcp_max_orphans ：INTEGER 缺省值是8192 系统所能处理不属于任何进程的TCP sockets最大数量。假如超过这个数量﹐那么不属于任何进程的连接会被立即reset，并同时显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐千万不要依赖这个或是人为的降低这个限制(这个值Redhat AS版本中设置为32768,但是很多防火墙修改的时候,建议该值修改为2000) tcp_abort_on_overflow ：BOOLEAN 缺省值是0 当守护进程太忙而不能接受新的连接，就象对方发送reset消息，默认值是false。这意味着当溢出的原因是因为一个偶然的猝发，那么连接将恢复状态。只有在你确信守护进程真的不能完成连接请求时才打开该选项，该选项会影响客户的使用。(对待已经满载的sendmail,apache这类服务的时候,这个可以很快让客户端终止连接,可以给予服务程序处理已有连接的缓冲机会,所以很多防火墙上推荐打开它) tcp_syncookies ：BOOLEAN 默认值是0 只有在内核编译时选择了CONFIG_SYNCOOKIES时才会发生作用。当出现syn等候队列出现溢出时象对方发送syncookies。目的是为了防止syn flood攻击。 注意：该选项千万不能用于那些没有收到攻击的高负载服务器，如果在日志中出现synflood消息，但是调查发现没有收到synflood攻击，而是合法用户的连接负载过高的原因，你应该调整其它参数来提高服务器性能。参考: tcp_max_syn_backlog tcp_synack_retries tcp_abort_on_overflow syncookie严重的违背TCP协议，不允许使用TCP扩展，可能对某些服务导致严重的性能影响(如SMTP转发)。(注意,该实现与BSD上面使用的tcp proxy一样,是违反了RFC中关于tcp连接的三次握手实现的,但是对于防御syn-flood的确很有用.) tcp_stdurg ：BOOLEAN 默认值为0 使用 TCP urg pointer 字段中的主机请求解释功能。大部份的主机都使用老旧的 BSD解释，因此如果您在Linux打开它﹐或会导致不能和它们正确沟通。 tcp_max_syn_backlog ：INTEGER 对于那些依然还未获得客户端确认的连接请求﹐需要保存在队列中最大数目。对于超过 128Mb 内存的系统﹐默认值是1024 ﹐低于 128Mb 的则为 128。如果服务器经常出现过载﹐可以尝试增加这个数字。警告﹗假如您将此值设为大于1024﹐最好修改 include/net/tcp.h 里面的 TCP_SYNQ_HSIZE ﹐以保持TCP_SYNQ_HSIZE*16&lt;=tcp_max_syn_backlog ﹐并且编进核心之内。(SYN Flood攻击利用TCP协议散布握手的缺陷，伪造虚假源IP地址发送大量TCP-SYN半打开连接到目标系统，最终导致目标系统Socket队列资源耗 尽而无法接受新的连接。为了应付这种攻击，现代Unix系统中普遍采用多连接队列处理的方式来缓冲(而不是解决)这种攻击，是用一个基本队列处理正常的完 全连接应用(Connect()和Accept() )，是用另一个队列单独存放半打开连接。这种双队列处理方式和其他一些系统内核措施(例如Syn-Cookies/Caches)联合应用时，能够比较有 效的缓解小规模的SYN Flood攻击(事实证明&lt;1000p/s)加大SYN队列长度可以容纳更多等待连接的网络连接数，所以对Server来说可以考虑增大该值.) tcp_window_scaling ：INTEGER 缺省值为1 该文件表示设置tcp/ip会话的滑动窗口大小是否可变。参数值为布尔值，为1时表示可变，为0时表示不可变。tcp/ip通常使用的窗口最大可达到 65535 字节，对于高速网络，该值可能太小，这时候如果启用了该功能，可以使tcp/ip滑动窗口大小增大数个数量级，从而提高数据传输的能力(RFC 1323)。（对普通地百M网络而言，关闭会降低开销，所以如果不是高速网络，可以考虑设置为0） tcp_timestamps ：BOOLEAN 缺省值为1 Timestamps 用在其它一些东西中﹐可以防范那些伪造的 sequence 号码。一条1G的宽带线路或许会重遇到带 out-of-line数值的旧sequence 号码(假如它是由于上次产生的)。Timestamp 会让它知道这是个 ‘旧封包’。(该文件表示是否启用以一种比超时重发更精确的方法（RFC 1323）来启用对 RTT 的计算；为了实现更好的性能应该启用这个选项。) tcp_sack ：BOOLEAN 缺省值为1 使用 Selective ACK﹐它可以用来查找特定的遗失的数据报— 因此有助于快速恢复状态。该文件表示是否启用有选择的应答（Selective Acknowledgment），这可以通过有选择地应答乱序接收到的报文来提高性能（这样可以让发送者只发送丢失的报文段）。(对于广域网通信来说这个选项应该启用，但是这会增加对 CPU 的占用。) tcp_fack ：BOOLEAN 缺省值为1 打开FACK拥塞避免和快速重传功能。(注意，当tcp_sack设置为0的时候，这个值即使设置为1也无效) tcp_dsack ：BOOLEAN 缺省值为1 允许TCP发送”两个完全相同”的SACK。 tcp_ecn ：BOOLEAN 缺省值为0 打开TCP的直接拥塞通告功能。 tcp_reordering ：INTEGER 默认值是3 TCP流中重排序的数据报最大数量 。 (一般有看到推荐把这个数值略微调整大一些,比如5) tcp_retrans_collapse ：BOOLEAN 缺省值为1 对于某些有bug的打印机提供针对其bug的兼容性。(一般不需要这个支持,可以关闭它) tcp_wmem(3个INTEGER变量)： min, default, max min：为TCP socket预留用于发送缓冲的内存最小值。每个tcp socket都可以在建议以后都可以使用它。默认值为4096(4K)。 default：为TCP socket预留用于发送缓冲的内存数量，默认情况下该值会影响其它协议使用的net.core.wmem_default 值，一般要低于net.core.wmem_default的值。默认值为16384(16K)。 max: 用于TCP socket发送缓冲的内存最大值。该值不会影响net.core.wmem_max，”静态”选择参数SO_SNDBUF则不受该值影响。默认值为131072(128K)。（对于服务器而言，增加这个参数的值对于发送数据很有帮助,在我的网络环境中,修改为了51200 131072 204800） tcp_rmem (3个INTEGER变量)： min, default, max min：为TCP socket预留用于接收缓冲的内存数量，即使在内存出现紧张情况下tcp socket都至少会有这么多数量的内存用于接收缓冲，默认值为8K。 default：为TCP socket预留用于接收缓冲的内存数量，默认情况下该值影响其它协议使用的net.core.wmem_default 值。该值决定了在tcp_adv_win_scale、tcp_app_win和tcp_app_win=0默认值情况下，TCP窗口大小为65535。默认值为87380 max：用于TCP socket接收缓冲的内存最大值。该值不会影响 net.core.wmem_max，”静态”选择参数 SO_SNDBUF则不受该值影响。默认值为 128K。默认值为87380*2 bytes。（可以看出，.max的设置最好是default的两倍,对于NAT来说主要该增加它,我的网络里为 51200 131072 204800） tcp_mem(3个INTEGER变量)：low, pressure, high low：当TCP使用了低于该值的内存页面数时，TCP不会考虑释放内存。(理想情况下，这个值应与指定给 tcp_wmem 的第 2 个值相匹配 - 这第 2 个值表明，最大页面大小乘以最大并发请求数除以页大小 (131072 * 300 / 4096)。 ) pressure：当TCP使用了超过该值的内存页面数量时，TCP试图稳定其内存使用，进入pressure模式，当内存消耗低于low值时则退出pressure状态。(理想情况下这个值应该是 TCP 可以使用的总缓冲区大小的最大值 (204800 * 300 / 4096)。 ) high：允许所有tcp sockets用于排队缓冲数据报的页面量。(如果超过这个值，TCP 连接将被拒绝，这就是为什么不要令其过于保守 (512000 * 300 / 4096) 的原因了。 在这种情况下，提供的价值很大，它能处理很多连接，是所预期的 2.5 倍；或者使现有连接能够传输 2.5 倍的数据。 我的网络里为192000 300000 732000) 一般情况下这些值是在系统启动时根据系统内存数量计算得到的。 tcp_app_win : INTEGER 默认值是31 保留max(window/2^tcp_app_win, mss)数量的窗口由于应用缓冲。当为0时表示不需要缓冲。 tcp_adv_win_scale : INTEGER 默认值为2 计算缓冲开销bytes/2^tcp_adv_win_scale(如果tcp_adv_win_scale &gt; 0)或者bytes-bytes/2^(-tcp_adv_win_scale)(如果tcp_adv_win_scale &lt;= 0）。 tcp_rfc1337 :BOOLEAN 缺省值为0 这个开关可以启动对于在RFC1337中描述的”tcp 的time-wait暗杀危机”问题的修复。启用后，内核将丢弃那些发往time-wait状态TCP套接字的RST 包. tcp_low_latency : BOOLEAN 缺省值为0 允许 TCP/IP 栈适应在高吞吐量情况下低延时的情况；这个选项一般情形是的禁用。(但在构建Beowulf 集群的时候,打开它很有帮助) tcp_westwood :BOOLEAN 缺省值为0 启用发送者端的拥塞控制算法，它可以维护对吞吐量的评估，并试图对带宽的整体利用情况进行优化；对于 WAN 通信来说应该启用这个选项。 tcp_bic :BOOLEAN 缺省值为0 为快速长距离网络启用 Binary Increase Congestion；这样可以更好地利用以 GB 速度进行操作的链接；对于 WAN 通信应该启用这个选项。","categories":[{"name":"系统","slug":"系统","permalink":"http://yoursite.com/categories/系统/"}],"tags":[{"name":"linux-sysctl","slug":"linux-sysctl","permalink":"http://yoursite.com/tags/linux-sysctl/"}]},{"title":"linux查看系统命令","slug":"linux系统信息查看","date":"2019-01-08T06:22:53.000Z","updated":"2019-01-08T06:22:53.000Z","comments":true,"path":"2019/01/08/linux系统信息查看/","link":"","permalink":"http://yoursite.com/2019/01/08/linux系统信息查看/","excerpt":"inux 查看系统信息命令是linux初学者必备的基础知识, 这些命令也非常有用, 因为进入linux第一件事就可能是首先查看系统信息, 因此必要的系统的学习一下这些linux系统信息命令还是非常有必要的!","text":"inux 查看系统信息命令是linux初学者必备的基础知识, 这些命令也非常有用, 因为进入linux第一件事就可能是首先查看系统信息, 因此必要的系统的学习一下这些linux系统信息命令还是非常有必要的! 12345678910111213141516171819202122232425262728293031323334353637# uname -a # 查看内核/操作系统/CPU信息 # head -n 1 /etc/issue # 查看操作系统版本 # cat /proc/cpuinfo # 查看CPU信息 # hostname # 查看计算机名 # lspci -tv # 列出所有PCI设备 # lsusb -tv # 列出所有USB设备 # lsmod # 列出加载的内核模块 # env # 查看环境变量资源 # free -m # 查看内存使用量和交换区使用量 # df -h # 查看各分区使用情况 # du -sh &lt;目录名&gt; # 查看指定目录的大小 # grep MemTotal /proc/meminfo # 查看内存总量 # grep MemFree /proc/meminfo # 查看空闲内存量 # uptime # 查看系统运行时间、用户数、负载 # cat /proc/loadavg # 查看系统负载磁盘和分区 # mount | column -t # 查看挂接的分区状态 # fdisk -l # 查看所有分区 # swapon -s # 查看所有交换分区 # hdparm -i /dev/hda # 查看磁盘参数(仅适用于IDE设备) # dmesg | grep IDE # 查看启动时IDE设备检测状况网络 # ifconfig # 查看所有网络接口的属性 # iptables -L # 查看防火墙设置 # route -n # 查看路由表 # netstat -lntp # 查看所有监听端口 # netstat -antp # 查看所有已经建立的连接 # netstat -s # 查看网络统计信息进程 # ps -ef # 查看所有进程 # top # 实时显示进程状态用户 # w # 查看活动用户 # id &lt;用户名&gt; # 查看指定用户信息 # last # 查看用户登录日志 # cut -d: -f1 /etc/passwd # 查看系统所有用户 # cut -d: -f1 /etc/group # 查看系统所有组 # crontab -l # 查看当前用户的计划任务服务 # chkconfig –list # 列出所有系统服务 # chkconfig –list | grep on # 列出所有启动的系统服务程序 # rpm -qa # 查看所有安装的软件包","categories":[{"name":"系统","slug":"系统","permalink":"http://yoursite.com/categories/系统/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"tcp参数调优","slug":"tcp参数调优","date":"2019-01-08T06:22:53.000Z","updated":"2019-01-08T06:22:53.000Z","comments":true,"path":"2019/01/08/tcp参数调优/","link":"","permalink":"http://yoursite.com/2019/01/08/tcp参数调优/","excerpt":"","text":"/etc/sysctl.conf 1234567891011121314151617181920212223net.ipv4.tcp_tw_reuse = 1net.ipv4.ip_local_port_range = 1024 65535net.core.rmem_max=16777216net.core.wmem_max=16777216net.ipv4.tcp_rmem=4096 87380 16777216net.ipv4.tcp_wmem=4096 65536 16777216net.ipv4.tcp_fin_timeout = 10net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_timestamps = 0net.ipv4.tcp_window_scaling = 0net.ipv4.tcp_sack = 0net.core.netdev_max_backlog = 30000net.ipv4.tcp_no_metrics_save=1net.core.somaxconn = 262144net.ipv4.tcp_syncookies = 0net.ipv4.tcp_max_orphans = 262144net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syn_retries = 2fs.file-max = 1024000net.nf_conntrack_max= 1024000net.ipv4.tcp_mem=786432 2097152 3145728 ulimit -a 中open files (-n) 1024000 修改 vi /etc/profile ulimit -n 1024000 生效：source /etc/profile cat /proc/sys/fs/file-max 修改：pending signals (-i) 128296 vi /etc/profile ulimit -i 128296 生效：source /etc/profile error, emfile 最大用户进程需要在90-nproc.conf vi /etc/security/limits.conf soft nofile 65535 hard nofile 65535 然后，一般来说，修改ulimit的数值，只需要修改/etc/security/limits.conf即可，但是这个参数需要修改/etc/security/limits.d/90-nproc.conf。centos 6.可以修改/etc/security/limits.d/90-nproc.conf，但centos 5.并没有90-nproc.conf这个文件，我这边是通过修改/etc/security/limits.conf。 netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’ CLOSE_WAIT 162 ESTABLISHED 10163 SYN_RECV 242","categories":[{"name":"系统","slug":"系统","permalink":"http://yoursite.com/categories/系统/"}],"tags":[{"name":"linux-sysctl","slug":"linux-sysctl","permalink":"http://yoursite.com/tags/linux-sysctl/"}]},{"title":"Mac iTerm使用","slug":"iTerm命令","date":"2018-12-20T09:23:57.000Z","updated":"2018-12-20T09:23:57.000Z","comments":true,"path":"2018/12/20/iTerm命令/","link":"","permalink":"http://yoursite.com/2018/12/20/iTerm命令/","excerpt":"Mac iTerm终端使用","text":"Mac iTerm终端使用 标签新建标签：command + t 关闭标签：command + w 切换标签：command + 数字 command + 左右方向键 切换全屏：command + enter 查找：command + f 分屏垂直分屏：command + d 水平分屏：command + shift + d 切换屏幕：command + option + 方向键 command + [ 或 command + ] 查看历史命令：command + ; 查看剪贴板历史：command + shift + h 其他清除当前行：ctrl + u 到行首：ctrl + a 到行尾：ctrl + e 前进后退：ctrl + f/b (相当于左右方向键) 上一条命令：ctrl + p 搜索命令历史：ctrl + r 删除当前光标的字符：ctrl + d 删除光标之前的字符：ctrl + h 删除光标之前的单词：ctrl + w 删除到文本末尾：ctrl + k 交换光标处文本：ctrl + t 清屏1：command + r 清屏2：ctrl + l","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://yoursite.com/categories/开发工具/"}],"tags":[{"name":"Mac iTerm","slug":"Mac-iTerm","permalink":"http://yoursite.com/tags/Mac-iTerm/"}]},{"title":"erlang防坑指南","slug":"erlang防坑指南","date":"2018-12-16T10:35:26.000Z","updated":"2018-12-16T10:35:26.000Z","comments":true,"path":"2018/12/16/erlang防坑指南/","link":"","permalink":"http://yoursite.com/2018/12/16/erlang防坑指南/","excerpt":"任何语言在使用中都会遇到这样那样的问题，erlang也是。这里整理下我遇到的一些问题，避免继续踩坑。说实话，“防坑指南”这个标题有点过于标新立异，不过还是希望能引起重视，避免在实际开发中重复犯这些问题。","text":"任何语言在使用中都会遇到这样那样的问题，erlang也是。这里整理下我遇到的一些问题，避免继续踩坑。说实话，“防坑指南”这个标题有点过于标新立异，不过还是希望能引起重视，避免在实际开发中重复犯这些问题。 ‘–’ 运算与 ‘++’运算1234567891&gt; [1,2,3,4] -- [1] -- [2]. [2,3,4]算是erlang经典的问题了。这是从后面算起的，先算 [1] -- [2] ，得到 [1] 后被 [1,2,3,4] --，最后得到 [2,3,4] &apos;++&apos;运算也是一样的，也是从后面开始算起。2&gt; [1,2,3,4] -- [1] ++ [2,3,4].[]另外，以下这种情况也要注意，只会减去遇到的第一个元素。3&gt; [1,2,3,2] -- [2].[1,3,2] erlang:function_exported()这个接口是用来检查模块函数是否导出，但是，如果模块没加载过，这个函数返回值就是false 1234563&gt; erlang:function_exported(odbc,start,0).false4&gt; odbc:start().ok5&gt; erlang:function_exported(odbc,start,0).true erlang:list_to_binary()如果参数是多层嵌套结构，就会被扁平化掉，使用 binary_to_list 不能转成原来的数据，也就是不可逆的。 123456&gt; list_to_binary([1,2,[3,4],5]) .&lt;&lt;1,2,3,4,5&gt;&gt;如果想可逆，可以使用 erlang:term_to_binary7&gt; binary_to_term(term_to_binary([1,2,[3,4],5])).[1,2,[3,4],5] random:uniform()这个用于生成随机数，返回一个随机数浮点数。但是，这个函数的随机初始种子是个定值，而且种子就放在进程字典，就是说每个进程生成的随机数都是一样的。坑爹啊。 1234567810&gt; spawn(fun() -&gt; io:format(&quot;~w ~w~n&quot;,[random:uniform(),random:uniform()]) end),ok.0.4435846174457203 0.7230402056221108ok11&gt; spawn(fun() -&gt; io:format(&quot;~w ~w~n&quot;,[random:uniform(),random:uniform()]) end),ok.0.4435846174457203 0.7230402056221108ok 所以，解决的方法就是进程启动后要重置随机数种子，然后再使用这个函数。 1213&gt; random:seed(erlang:now()), random:uniform().0.4691405130019146 io_lib:char_list()这个函数在R15和R16下运行结果可能是相反的。 123456789R15下：Eshell V5.9.3.1 (abort with ^G)1&gt; io_lib:char_list([10100,10600,20100]).falseR16下：Eshell V5.10.1 (abort with ^G) 1&gt; io_lib:char_list([10100,10600,20100]). true 不同类型数据比较比较公式为：number &lt; atom &lt; reference &lt; fun &lt; port &lt; pid &lt; tuple &lt; list &lt; bit string 系统限制123451. mnesia或dets有2G限制（无法定制）2. ets表最大数量默认1400（可用 ERL_MAX_ETS_TABLES 定制）3. 原子最大数量默认 1048576 （可用 +t 定制）4. 进程最大数量默认 32768 （可用 +P 定制， 范围1024-134217727）5. 端口/文件句柄最大数量默认 16384 （可用 +Q 定制， 范围1024-134217727）","categories":[{"name":"开发语言","slug":"开发语言","permalink":"http://yoursite.com/categories/开发语言/"}],"tags":[{"name":"erlang","slug":"erlang","permalink":"http://yoursite.com/tags/erlang/"}]},{"title":"account","slug":"account","date":"2018-12-16T10:35:26.000Z","updated":"2018-12-16T10:35:26.000Z","comments":true,"path":"2018/12/16/account/","link":"","permalink":"http://yoursite.com/2018/12/16/account/","excerpt":"","text":"代码账号12username:good-leafmail:rwzgnyyj 软件账号12username:yangyajun-softmail:yangyajun_c","categories":[{"name":"账号","slug":"账号","permalink":"http://yoursite.com/categories/账号/"}],"tags":[{"name":"账号","slug":"账号","permalink":"http://yoursite.com/tags/账号/"}]},{"title":"rabbitmq安装","slug":"rabbitmq安装","date":"2018-12-14T09:23:57.000Z","updated":"2018-12-14T09:23:57.000Z","comments":true,"path":"2018/12/14/rabbitmq安装/","link":"","permalink":"http://yoursite.com/2018/12/14/rabbitmq安装/","excerpt":"版本：rabbitmq-server-3.6.6-1.el6.noarch.rpm","text":"版本：rabbitmq-server-3.6.6-1.el6.noarch.rpm 安装脚本1234567891011121314151617181920212223242526sudo sucd /tmp &amp;&amp; wget https://yangyajun-soft.github.io/rabbitmq3.6.6/rabbitmq-server-3.6.6-1.el6.noarch.rpmyum install -y rabbitmq-server-3.6.6-1.el6.noarch.rpmchown rabbitmq:rabbitmq /etc/rabbitmqexit# set cookiesudo su rabbitmqecho cookie &gt; /var/lib/rabbitmq/.erlang.cookiechmod u=r,g=,o= /var/lib/rabbitmq/.erlang.cookiewget https://yangyajun-soft.github.io//rabbitmq3.6.6/rabbitmq.config -O /etc/rabbitmq/rabbitmq.config# startrabbitmq-server -detached# join clusterrabbitmqctl stop_apprabbitmqctl join_cluster rabbit@hostrabbitmqctl start_app# configrabbitmqctl set_policy ha-backup \"^\" '&#123;\"ha-mode\":\"exactly\", \"ha-params\":2, \"ha-sync-mode\":\"automatic\"&#125;'rabbitmq-plugins enable rabbitmq_management# add adminrabbitmqctl add_user admin passwordrabbitmqctl set_permissions -p \"/\" admin '.*' '.*' '.*'rabbitmqctl set_user_tags admin administrator# add userrabbitmqctl add_user user passwordrabbitmqctl set_permissions -p \"/\" user '.*' '.*' '.*' 配置文件 enabled_plugins 1[rabbitmq_management,rabbitmq_tracing]. rabbitmq.config 12345678[&#123;rabbit, [&#123;disk_free_limit, 5242880&#125; ,&#123;vm_memory_high_watermark, 0.8&#125; ,&#123;loopback_users, []&#125; ]&#125;,&#123;rabbitmq_management, [&#123;listener, [&#123;port, 8080&#125;]&#125;]&#125;&#123;rabbitmq_management_agent, [ &#123;force_fine_statistics, false&#125; ] &#125;].","categories":[{"name":"开源框架","slug":"开源框架","permalink":"http://yoursite.com/categories/开源框架/"}],"tags":[{"name":"rabbitmq安装","slug":"rabbitmq安装","permalink":"http://yoursite.com/tags/rabbitmq安装/"}]},{"title":"redis安装","slug":"redis安装","date":"2018-12-14T09:23:57.000Z","updated":"2018-12-14T09:23:57.000Z","comments":true,"path":"2018/12/14/redis安装/","link":"","permalink":"http://yoursite.com/2018/12/14/redis安装/","excerpt":"版本：redis-3.2.8-1.el6.remi.x86_64.rpm","text":"版本：redis-3.2.8-1.el6.remi.x86_64.rpm 123456789101112131415161718sudo sucd /tmp &amp;&amp; wget https://yangyajun-soft.github.io/redis/redis-3.2.8-1.el6.remi.x86_64.rpmyum install -y redis-3.2.8-1.el6.remi.x86_64.rpmsu sankuaimkdir -p /opt/xxx/apps/rediscd /opt/xxx/apps/redis## 6379mkdir -p /opt/xxx/appdatas/redis6379wget https://yangyajun-soft.github.io/redis/redis_6379_3.conf -O 6379.confredis-server /opt/xxx/apps/redis/6379.conf## 6380mkdir -p /opt/xxx/appdatas/redis6380wget https://yangyajun-soft.github.io/redis/redis_6380_3.conf -O 6380.conf## 6381mkdir -p /opt/xxx/appdatas/redis6381wget https://yangyajun-soft.github.io/redis/redis_6381_3.conf -O 6381.confexitexit","categories":[{"name":"开源框架","slug":"开源框架","permalink":"http://yoursite.com/categories/开源框架/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"hexo 安装","slug":"hexo安装","date":"2018-12-14T09:23:57.000Z","updated":"2018-12-14T09:23:57.000Z","comments":true,"path":"2018/12/14/hexo安装/","link":"","permalink":"http://yoursite.com/2018/12/14/hexo安装/","excerpt":"","text":"git设置12git config --global user.name \"good-leaf\"git config --global user.email \"rwzgnyyj@xxx.com\" hexo安装1234567npm install -g hexo-clicdhexo init blogcd blognpm installhexo servernpm install --save hexo-deployer-git hexo配置添加git地址：使用ssh时，需要将本机ssh key添加到github上，并且选择ssh访问方式。 1234deploy: type: git repo: git@github.com:good-leaf/good-leaf.github.io.git branch: master 修改端口：vi _config.yml 1234server: port: 4001 compress: true header: true 搜索支持： 1234567npm install hexo-generator-searchdb --savesearch: path: search.xml field: post format: html limit: 10000 更换主题：访问页面显示123456789101112extends partial/layoutblock container include mixins/post +posts()block pagination include mixins/paginator +home()block copyright include partial/copyright 解决：npm install –save hexo-renderer-jade","categories":[{"name":"开源框架","slug":"开源框架","permalink":"http://yoursite.com/categories/开源框架/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]}]}